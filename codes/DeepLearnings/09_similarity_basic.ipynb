{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 문장 임베딩 활용","metadata":{}},{"cell_type":"code","source":"# 문장 유사도 계산\nfrom sentence_transformers import SentenceTransformer\n\nmodel_sentence = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T06:40:08.575265Z","iopub.execute_input":"2025-02-06T06:40:08.575695Z","iopub.status.idle":"2025-02-06T06:40:10.067698Z","shell.execute_reply.started":"2025-02-06T06:40:08.575651Z","shell.execute_reply":"2025-02-06T06:40:10.066090Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"words = ['학교', '공부', '게임', '자전거']\n\ndense_embedded = model_sentence.encode(words)\ndense_embedded\nlen(dense_embedded[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T06:41:26.789470Z","iopub.execute_input":"2025-02-06T06:41:26.789855Z","iopub.status.idle":"2025-02-06T06:41:26.882595Z","shell.execute_reply.started":"2025-02-06T06:41:26.789830Z","shell.execute_reply":"2025-02-06T06:41:26.881467Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcd9d30b472241439046111cf799842a"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"768"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\ncosine_similarity(dense_embedded)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T06:44:18.247631Z","iopub.execute_input":"2025-02-06T06:44:18.248026Z","iopub.status.idle":"2025-02-06T06:44:18.259279Z","shell.execute_reply.started":"2025-02-06T06:44:18.247993Z","shell.execute_reply":"2025-02-06T06:44:18.257653Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"array([[0.9999999 , 0.59507424, 0.30069774, 0.20964187],\n       [0.59507424, 0.9999998 , 0.41403902, 0.16175744],\n       [0.30069774, 0.41403902, 1.0000001 , 0.29132563],\n       [0.20964187, 0.16175744, 0.29132563, 1.0000001 ]], dtype=float32)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"sentences = [\n    \"그 식당은 파리를 날린다\",\n    \"그 식당에는 손님이 없다\",\n    # \"그 식당에서는 드론을 날린다\",\n    # \"파리가 식당에 날아다닌다\",\n    # \"학생이 자전거타고 학교에 간다\",\n    \"오늘 날씨가 정말 좋네요.\",\n    \"오늘 날씨가 맑고 기분이 좋아요.\",\n    \"인공지능을 활용하면 업무 효율을 높일 수 있다.\",\n    \"AI 기술을 적용하면 생산성이 향상된다.\",\n    \"강아지는 사람에게 충성심이 강한 동물이다.\",\n    \"주식시장은 변동성이 크고 예측하기 어렵다.\"\n]\n# sentences = [\n#     \"우리 팀은 이번 시즌 5연패를 기록하며 순위가 하락했다.\",  # (1) 연속 패배\n#     \"그 선수는 연패를 끊기 위해 전략을 변경했다.\",  # (1) 연속 패배\n#     \"챔피언십 경기에서 연패를 당한 팀은 다음 시즌을 대비하고 있다.\",  # (1) 연속 패배\n#     \"이 건물의 기둥은 정교한 연패 문양으로 장식되어 있다.\",  # (2) 연속적인 무늬\n#     \"고대 유적에서는 독특한 연패 형식의 조각을 볼 수 있다.\",  # (2) 연속적인 무늬\n#     \"그 도자기의 가장자리는 연패 무늬로 아름답게 꾸며져 있었다.\",  # (2) 연속적인 무늬\n#     \"그 선수는 대회에서 3년 연속 우승하며 연패의 위업을 달성했다.\",  # (3) 연속 재패\n#     \"우리 팀은 세계 챔피언십에서 2연패를 기록하며 최강의 자리를 유지했다.\"  # (3) 연속 재패\n# ]\nsentence_embeddings = model_sentence.encode(sentences)\n\nsimilarities = model_sentence.similarity(sentence_embeddings, sentence_embeddings)\n# similarities = model_sentence.similarity([sentence_embeddings[-4]], sentence_embeddings)\nsimilarities","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:22:29.338013Z","iopub.execute_input":"2025-02-06T07:22:29.338396Z","iopub.status.idle":"2025-02-06T07:22:29.572410Z","shell.execute_reply.started":"2025-02-06T07:22:29.338356Z","shell.execute_reply":"2025-02-06T07:22:29.571378Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66999ff323414db5a57103a88557b964"}},"metadata":{}},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"tensor([[ 1.0000,  0.6306, -0.0144, -0.0135,  0.0767,  0.1518,  0.1863,  0.1206],\n        [ 0.6306,  1.0000,  0.0049,  0.0031,  0.0356,  0.1423,  0.1492,  0.1533],\n        [-0.0144,  0.0049,  1.0000,  0.9317,  0.1768,  0.1984,  0.1988,  0.1081],\n        [-0.0135,  0.0031,  0.9317,  1.0000,  0.1743,  0.1640,  0.1692,  0.1034],\n        [ 0.0767,  0.0356,  0.1768,  0.1743,  1.0000,  0.8091,  0.1696,  0.2261],\n        [ 0.1518,  0.1423,  0.1984,  0.1640,  0.8091,  1.0000,  0.2135,  0.1819],\n        [ 0.1863,  0.1492,  0.1988,  0.1692,  0.1696,  0.2135,  1.0000,  0.2197],\n        [ 0.1206,  0.1533,  0.1081,  0.1034,  0.2261,  0.1819,  0.2197,  1.0000]])"},"metadata":{}}],"execution_count":40},{"cell_type":"markdown","source":"## 기존 라이브러리 활용","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import models\n\nword_embedding_layers = models.Transformer('klue/roberta-base')\nword_embedding_layers # 기존 학습된 모델에서 임베딩 층만(transformer layer)만 가져옴\nword_embedding_layers.get_word_embedding_dimension()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:15:56.530856Z","iopub.execute_input":"2025-02-06T07:15:56.531347Z","iopub.status.idle":"2025-02-06T07:15:56.982612Z","shell.execute_reply.started":"2025-02-06T07:15:56.531285Z","shell.execute_reply":"2025-02-06T07:15:56.981632Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"768"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"# output 구성\npooling_layer = models.Pooling(word_embedding_layers.get_word_embedding_dimension())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:16:15.367938Z","iopub.execute_input":"2025-02-06T07:16:15.368274Z","iopub.status.idle":"2025-02-06T07:16:15.372578Z","shell.execute_reply.started":"2025-02-06T07:16:15.368245Z","shell.execute_reply":"2025-02-06T07:16:15.371482Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"custom_sentence_model = SentenceTransformer(modules=[word_embedding_layers, pooling_layer]) # \ncustom_sentence_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:19:29.692075Z","iopub.execute_input":"2025-02-06T07:19:29.692558Z","iopub.status.idle":"2025-02-06T07:19:29.709851Z","shell.execute_reply.started":"2025-02-06T07:19:29.692521Z","shell.execute_reply":"2025-02-06T07:19:29.708768Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"SentenceTransformer(\n  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: RobertaModel \n  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"## 활용 \ncustom_sentence_embeddings = custom_sentence_model.encode(sentences)\n\nsimilarities = custom_sentence_model.similarity(custom_sentence_embeddings, custom_sentence_embeddings)\n# similarities = model_sentence.similarity([sentence_embeddings[-4]], sentence_embeddings)\nsimilarities","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:22:42.830058Z","iopub.execute_input":"2025-02-06T07:22:42.830513Z","iopub.status.idle":"2025-02-06T07:22:43.085008Z","shell.execute_reply.started":"2025-02-06T07:22:42.830480Z","shell.execute_reply":"2025-02-06T07:22:43.084149Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41b41a895b4045eb9d819e22f8e06178"}},"metadata":{}},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"tensor([[1.0000, 0.8397, 0.7226, 0.6604, 0.6811, 0.7108, 0.7044, 0.6436],\n        [0.8397, 1.0000, 0.7199, 0.6881, 0.6921, 0.7127, 0.7380, 0.6835],\n        [0.7226, 0.7199, 1.0000, 0.9347, 0.7160, 0.7274, 0.7303, 0.7175],\n        [0.6604, 0.6881, 0.9347, 1.0000, 0.6894, 0.6999, 0.7078, 0.7067],\n        [0.6811, 0.6921, 0.7160, 0.6894, 1.0000, 0.9312, 0.7470, 0.7737],\n        [0.7108, 0.7127, 0.7274, 0.6999, 0.9312, 1.0000, 0.7709, 0.7775],\n        [0.7044, 0.7380, 0.7303, 0.7078, 0.7470, 0.7709, 1.0000, 0.7603],\n        [0.6436, 0.6835, 0.7175, 0.7067, 0.7737, 0.7775, 0.7603, 1.0000]])"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"len(custom_sentence_embeddings[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:22:35.867071Z","iopub.execute_input":"2025-02-06T07:22:35.867467Z","iopub.status.idle":"2025-02-06T07:22:35.873539Z","shell.execute_reply.started":"2025-02-06T07:22:35.867439Z","shell.execute_reply":"2025-02-06T07:22:35.872495Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"768"},"metadata":{}}],"execution_count":42},{"cell_type":"markdown","source":"## 이미지 유사도 ","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer(\"sentence-transformers/clip-ViT-B-32\")\n\nsentences = [\n    \"That is a happy person\",\n    \"That is a happy dog\",\n    \"That is a very happy person\",\n    \"Today is a sunny day\"\n]\nembeddings = model.encode(sentences)\n\nsimilarities = model.similarity(embeddings, embeddings)\nprint(similarities.shape)\n# [4, 4]","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}