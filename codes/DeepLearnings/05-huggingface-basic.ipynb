{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets huggingface_hub fsspec==2024.10.0 -qqq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T06:49:29.245090Z","iopub.execute_input":"2025-02-04T06:49:29.245297Z","iopub.status.idle":"2025-02-04T06:49:36.626883Z","shell.execute_reply.started":"2025-02-04T06:49:29.245278Z","shell.execute_reply":"2025-02-04T06:49:36.625808Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\ns3fs 2024.9.0 requires fsspec==2024.9.0.*, but you have fsspec 2024.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## hugging face \n- 여러 회사들이 개발한 모델이나 제공하는 데이터셋을 편리하게 사용하는 인터페이스 제공","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T06:53:09.580271Z","iopub.execute_input":"2025-02-04T06:53:09.580636Z","iopub.status.idle":"2025-02-04T06:53:16.963711Z","shell.execute_reply.started":"2025-02-04T06:53:09.580600Z","shell.execute_reply":"2025-02-04T06:53:16.963042Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### BERT 모델 활용 준비\n- https://huggingface.co/google-bert/bert-base-uncased","metadata":{}},{"cell_type":"code","source":"AutoModel.from_pretrained('google-bert/bert-base-uncased')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T06:58:02.479905Z","iopub.execute_input":"2025-02-04T06:58:02.480352Z","iopub.status.idle":"2025-02-04T06:58:17.555778Z","shell.execute_reply.started":"2025-02-04T06:58:02.480328Z","shell.execute_reply":"2025-02-04T06:58:17.554867Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df5a11b00b394e18b5163cbc8fb4d616"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"974889e307634d86b5268b563b0f6213"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x BertLayer(\n        (attention): BertAttention(\n          (self): BertSdpaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T06:58:32.097156Z","iopub.execute_input":"2025-02-04T06:58:32.097792Z","iopub.status.idle":"2025-02-04T06:58:33.540864Z","shell.execute_reply.started":"2025-02-04T06:58:32.097760Z","shell.execute_reply":"2025-02-04T06:58:33.540143Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f093108085cb4970b350f173259fd7bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0217049ccb404c91ab0790bed40e893c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"226f7748227a4e5e898acb9b2d689b62"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"BertTokenizerFast(name_or_path='google-bert/bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}\n)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"bert_model = AutoModel.from_pretrained('google-bert/bert-base-uncased')\nbert_tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T06:59:14.919962Z","iopub.execute_input":"2025-02-04T06:59:14.920258Z","iopub.status.idle":"2025-02-04T06:59:15.283358Z","shell.execute_reply.started":"2025-02-04T06:59:14.920235Z","shell.execute_reply":"2025-02-04T06:59:15.282654Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"type(bert_model), type(bert_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T06:59:47.091963Z","iopub.execute_input":"2025-02-04T06:59:47.092254Z","iopub.status.idle":"2025-02-04T06:59:47.097662Z","shell.execute_reply.started":"2025-02-04T06:59:47.092231Z","shell.execute_reply":"2025-02-04T06:59:47.096725Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(transformers.models.bert.modeling_bert.BertModel,\n transformers.models.bert.tokenization_bert_fast.BertTokenizerFast)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"text = f'What is Hugging Face Transformer ?'\nencoded_input = bert_tokenizer(text, return_tensors='pt') # 학습 완료된 형태의 벡터로 결과 리턴\nbert_out = bert_model(**encoded_input)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T07:04:02.157452Z","iopub.execute_input":"2025-02-04T07:04:02.157792Z","iopub.status.idle":"2025-02-04T07:04:02.376796Z","shell.execute_reply.started":"2025-02-04T07:04:02.157765Z","shell.execute_reply":"2025-02-04T07:04:02.376024Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"type(encoded_input), encoded_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T07:04:18.181154Z","iopub.execute_input":"2025-02-04T07:04:18.181436Z","iopub.status.idle":"2025-02-04T07:04:18.192371Z","shell.execute_reply.started":"2025-02-04T07:04:18.181413Z","shell.execute_reply":"2025-02-04T07:04:18.191416Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(transformers.tokenization_utils_base.BatchEncoding,\n {'input_ids': tensor([[  101,  2054,  2003, 17662,  2227, 10938,  2121,  1029,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"type(bert_out), bert_out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T07:04:53.398480Z","iopub.execute_input":"2025-02-04T07:04:53.398817Z","iopub.status.idle":"2025-02-04T07:04:53.430287Z","shell.execute_reply.started":"2025-02-04T07:04:53.398788Z","shell.execute_reply":"2025-02-04T07:04:53.429747Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions,\n BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.2861, -0.1240,  0.2815,  ..., -0.4858,  0.2977,  0.5689],\n          [-0.1944, -0.3199, -0.1468,  ...,  0.1556,  0.3000,  0.1225],\n          [-0.3892, -0.5491,  0.5673,  ..., -0.3892, -0.1358,  1.1888],\n          ...,\n          [-0.4400, -0.3780,  0.2772,  ..., -1.2009, -0.6481, -0.3628],\n          [-0.2662, -0.4287, -0.5090,  ..., -0.2293,  0.2339, -0.0035],\n          [ 0.7004,  0.1887, -0.1690,  ...,  0.3775, -0.3948, -0.4581]]],\n        grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8927, -0.2168, -0.3380,  0.6888,  0.1770, -0.2012,  0.8864,  0.2803,\n          -0.2021, -0.9999,  0.2056,  0.5897,  0.9804,  0.2280,  0.9489, -0.7399,\n          -0.1644, -0.5802,  0.2375, -0.5985,  0.5917,  0.9975,  0.4738,  0.3131,\n           0.3709,  0.6705, -0.7104,  0.9292,  0.9572,  0.7037, -0.7406,  0.1027,\n          -0.9869, -0.1425, -0.4543, -0.9851,  0.2298, -0.7493,  0.0449,  0.0586,\n          -0.8772,  0.0972,  0.9996, -0.7744,  0.1434, -0.3338, -1.0000,  0.2537,\n          -0.9010,  0.1800,  0.3688, -0.1177,  0.0341,  0.3418,  0.4584,  0.1481,\n          -0.2194,  0.0254, -0.2478, -0.4584, -0.6316,  0.3551, -0.2900, -0.8909,\n           0.1858,  0.3587, -0.1046, -0.2769, -0.0404, -0.0665,  0.8634,  0.1866,\n           0.2582, -0.8455, -0.0555,  0.2198, -0.6033,  1.0000, -0.4717, -0.9719,\n           0.3677,  0.3916,  0.5117,  0.2328,  0.2341, -1.0000,  0.2465,  0.0020,\n          -0.9893,  0.1726,  0.3957, -0.1464,  0.4211,  0.5381, -0.5413, -0.1500,\n          -0.0897, -0.2511, -0.0841,  0.0145,  0.0175, -0.2228, -0.2707, -0.3130,\n           0.1549, -0.3798, -0.5240,  0.4040, -0.0894,  0.6189,  0.4304, -0.2664,\n           0.3037, -0.9478,  0.4771, -0.3409, -0.9833, -0.5436, -0.9834,  0.7001,\n          -0.0170, -0.2502,  0.9603,  0.3716,  0.3533, -0.0795, -0.1658, -1.0000,\n          -0.1310, -0.3873, -0.0313, -0.1761, -0.9727, -0.9589,  0.5703,  0.9557,\n           0.1790,  0.9992, -0.1374,  0.9358,  0.1509, -0.4146, -0.1979, -0.4049,\n           0.5679,  0.1311, -0.5907,  0.2062, -0.0465, -0.2559, -0.4462, -0.1720,\n          -0.2087, -0.9450, -0.2677,  0.9560, -0.0570, -0.5524,  0.2805, -0.2076,\n          -0.2803,  0.8534,  0.3774,  0.2679, -0.2006,  0.2773,  0.1096,  0.3276,\n          -0.8475,  0.4170,  0.3690, -0.2690, -0.4372, -0.9742, -0.2680,  0.4626,\n           0.9860,  0.7505,  0.2476,  0.1068, -0.2768,  0.0796, -0.9493,  0.9750,\n          -0.0659,  0.2016,  0.0108,  0.2400, -0.8558, -0.0223,  0.7902,  0.0933,\n          -0.8379,  0.0645, -0.4536, -0.3833, -0.4141,  0.3447, -0.2576, -0.2941,\n           0.1435,  0.9338,  0.9631,  0.7053, -0.3448,  0.4664, -0.8644, -0.4054,\n           0.0285,  0.1365,  0.0533,  0.9906, -0.4149, -0.0239, -0.9182, -0.9800,\n          -0.0762, -0.8648,  0.0261, -0.5656,  0.4197,  0.3234, -0.0060,  0.3286,\n          -0.9713, -0.7893,  0.3192, -0.2709,  0.4259, -0.2004,  0.6178,  0.5495,\n          -0.5938,  0.7884,  0.9294, -0.4625, -0.7554,  0.8117, -0.2445,  0.8622,\n          -0.5125,  0.9822,  0.3017,  0.3433, -0.9032, -0.3619, -0.8662, -0.1790,\n           0.0744, -0.2004,  0.4405,  0.5935,  0.2826,  0.4486, -0.5263,  0.9942,\n          -0.7878, -0.9534,  0.0898,  0.0803, -0.9882,  0.3190,  0.2991, -0.2950,\n          -0.3741, -0.5758, -0.9661,  0.8188,  0.0642,  0.9824, -0.1165, -0.8632,\n          -0.4445, -0.9273, -0.2273, -0.1606,  0.3240, -0.1840, -0.9603,  0.4982,\n           0.5643,  0.3729, -0.3387,  0.9959,  1.0000,  0.9656,  0.8954,  0.8671,\n          -0.9907, -0.4300,  1.0000, -0.8658, -1.0000, -0.9431, -0.5489,  0.3358,\n          -1.0000, -0.2246,  0.0596, -0.9060,  0.1546,  0.9748,  0.9833, -1.0000,\n           0.8335,  0.9149, -0.6330,  0.5652, -0.3784,  0.9699,  0.5466,  0.4421,\n          -0.2166,  0.3806, -0.7372, -0.8070,  0.0450, -0.4263,  0.9399,  0.1244,\n          -0.7342, -0.8913, -0.0230, -0.1296, -0.3587, -0.9628, -0.1975, -0.2553,\n           0.6635,  0.0778,  0.2894, -0.6930,  0.1822, -0.3358,  0.3439,  0.6653,\n          -0.9327, -0.4664,  0.4601, -0.5475, -0.2050, -0.9655,  0.9635, -0.2566,\n           0.0392,  1.0000, -0.2223, -0.8373,  0.5629,  0.1440, -0.1829,  1.0000,\n           0.6192, -0.9753, -0.5395,  0.4657, -0.4117, -0.4633,  0.9988, -0.1978,\n          -0.0229,  0.2679,  0.9708, -0.9872,  0.9154, -0.8793, -0.9646,  0.9633,\n           0.9299, -0.3053, -0.6248,  0.0967, -0.5092,  0.2096, -0.9580,  0.4626,\n           0.4736, -0.0684,  0.8688, -0.7482, -0.5213,  0.2724, -0.2439,  0.4228,\n           0.5958,  0.3846, -0.2128,  0.0770, -0.3050, -0.2265, -0.9740, -0.0061,\n           1.0000,  0.0787, -0.1675, -0.3005, -0.0236, -0.2230,  0.4162,  0.4930,\n          -0.2068, -0.8361,  0.0544, -0.9527, -0.9850,  0.6959,  0.1120, -0.3319,\n           0.9998,  0.2234,  0.1304,  0.0677,  0.5606,  0.0599,  0.5957,  0.3653,\n           0.9761, -0.2729,  0.5694,  0.7891, -0.3356, -0.2359, -0.6083, -0.0463,\n          -0.9103,  0.2166, -0.9507,  0.9621,  0.2586,  0.2906,  0.1903,  0.1041,\n           1.0000, -0.2191,  0.5760, -0.3025,  0.7975, -0.9853, -0.8264, -0.3402,\n          -0.0332, -0.1544, -0.2458,  0.1644, -0.9624,  0.1901, -0.0151, -0.9797,\n          -0.9879,  0.5015,  0.7776,  0.0271, -0.8110, -0.6308, -0.6075,  0.0438,\n          -0.1325, -0.9349,  0.3766, -0.1314,  0.3573, -0.1970,  0.5270,  0.4722,\n           0.7048, -0.0889, -0.0974, -0.1427, -0.8328,  0.7841, -0.7673, -0.3664,\n          -0.1707,  1.0000, -0.3443,  0.5206,  0.7559,  0.6169, -0.1356,  0.2043,\n           0.6112,  0.2341, -0.4171, -0.1489, -0.5577, -0.3198,  0.6428, -0.1231,\n           0.4277,  0.7427,  0.4075,  0.0616, -0.0792,  0.0166,  0.9981,  0.0030,\n           0.0267, -0.3912,  0.0120, -0.2945, -0.3567,  1.0000,  0.2322, -0.1991,\n          -0.9866, -0.2705, -0.8715,  0.9999,  0.8174, -0.7457,  0.5829,  0.1895,\n          -0.1248,  0.7283, -0.1223, -0.2725,  0.1529,  0.1203,  0.9527, -0.4667,\n          -0.9689, -0.6062,  0.3277, -0.9624,  0.9949, -0.4787, -0.1807, -0.3807,\n           0.2525,  0.4742, -0.1714, -0.9829, -0.1464,  0.1400,  0.9484,  0.1634,\n          -0.5581, -0.9132,  0.0093,  0.3085, -0.3748, -0.9228,  0.9574, -0.9837,\n           0.3121,  1.0000,  0.3917, -0.7020,  0.0645, -0.5095,  0.2399,  0.2801,\n           0.6562, -0.9562, -0.2631, -0.1255,  0.1629, -0.0169,  0.0932,  0.6302,\n           0.0810, -0.4718, -0.5241,  0.0077,  0.4441,  0.7294, -0.2719, -0.0885,\n           0.0732, -0.0881, -0.9125, -0.2178, -0.2836, -0.9990,  0.7833, -1.0000,\n          -0.1099, -0.2631, -0.2100,  0.8335,  0.2648,  0.1911, -0.7381, -0.2658,\n           0.7107,  0.7110, -0.1251,  0.3828, -0.6755,  0.0873,  0.0396,  0.0427,\n          -0.1381,  0.8009, -0.1574,  1.0000,  0.1060, -0.5729, -0.9602,  0.2016,\n          -0.2212,  1.0000, -0.9064, -0.9450,  0.2776, -0.5822, -0.8275,  0.2488,\n           0.1587, -0.5893, -0.4527,  0.9579,  0.9010, -0.5838,  0.2495, -0.2789,\n          -0.3040,  0.0305,  0.0799,  0.9836,  0.2179,  0.8672,  0.3521,  0.2067,\n           0.9714,  0.1982,  0.4402, -0.0609,  1.0000,  0.2419, -0.9052,  0.5118,\n          -0.9820, -0.1909, -0.9481,  0.1991,  0.1371,  0.8894, -0.1362,  0.9575,\n           0.2179, -0.0588,  0.0603,  0.2818,  0.3422, -0.9296, -0.9850, -0.9849,\n           0.2775, -0.3529,  0.0059,  0.1892,  0.0701,  0.3609,  0.3738, -1.0000,\n           0.9238,  0.3269,  0.6361,  0.9456,  0.4305,  0.2411,  0.2012, -0.9828,\n          -0.9636, -0.3227, -0.1772,  0.6545,  0.4990,  0.8670,  0.2921, -0.4694,\n          -0.3183,  0.1586, -0.5634, -0.9917,  0.3077,  0.1402, -0.9520,  0.9572,\n          -0.2563, -0.1492,  0.4063, -0.3578,  0.9058,  0.7198,  0.3035,  0.1296,\n           0.4743,  0.8598,  0.9431,  0.9783, -0.3746,  0.8090,  0.0413,  0.3997,\n           0.5601, -0.9436,  0.1555,  0.2303, -0.2747,  0.1821, -0.1485, -0.9609,\n           0.3824, -0.2864,  0.4863, -0.3335,  0.1721, -0.3158, -0.0942, -0.6705,\n          -0.4317,  0.6195,  0.3453,  0.8850,  0.5842, -0.0386, -0.3996, -0.0965,\n          -0.4096, -0.9083,  0.8839,  0.0153, -0.0672,  0.2185, -0.1712,  0.6803,\n          -0.1577, -0.3550, -0.2919, -0.7571,  0.8181, -0.2963, -0.5045, -0.4923,\n           0.4660,  0.3432,  0.9980, -0.4113, -0.2882, -0.1151, -0.2002,  0.3719,\n          -0.2249, -1.0000,  0.2678,  0.1073,  0.2634,  0.0858,  0.3647, -0.0057,\n          -0.9713, -0.1538,  0.1786,  0.1823, -0.4139, -0.0356,  0.5265,  0.7408,\n           0.6020,  0.8108, -0.1572,  0.4547,  0.5813, -0.3497, -0.6378,  0.9208]],\n        grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None))"},"metadata":{}}],"execution_count":10}]}